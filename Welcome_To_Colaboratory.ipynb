{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowthambalachandhiran/VisualQuestionAnswering/blob/master/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xitplqMNk_Hc",
        "outputId": "ed4f60d2-878d-4056-c438-352dac39a112",
        "colab": {
          "height": 420
        }
      },
      "source": [
        "#@title Introducing Colaboratory { display-mode: \"form\" }\n",
        "#@markdown This 3-minute video gives an overview of the key features of Colaboratory:\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('inN8seMm7UI', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"400\"\n",
              "            src=\"https://www.youtube.com/embed/inN8seMm7UI\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f956e9dda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "The document you are reading is a  [Jupyter notebook](https://jupyter.org/), hosted in Colaboratory. It is not a static page, but an interactive environment that lets you write and execute code in Python and other languages.\n",
        "\n",
        "For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJr_9dXGpJ05",
        "outputId": "5626194c-e802-4293-942d-2908885c3c1f",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_day = 24 * 60 * 60\n",
        "seconds_in_a_day"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\".\n",
        "\n",
        "All cells modify the same global state, so variables that you define by executing a cell can be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gE-Ez1qtyIA",
        "outputId": "8d2e4259-4682-4e19-b683-7b9087f28820",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "For more information about working with Colaboratory notebooks, see [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "Learn how to make the most of Python, Jupyter, Colaboratory, and related tools with these resources:\n",
        "\n",
        "### Working with Notebooks in Colaboratory\n",
        "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "- <img src=\"/img/new.png\" height=\"20px\" align=\"left\" hspace=\"4px\" alt=\"New\"></img>\n",
        " [TensorFlow 2 in Colab](/notebooks/tensorflow_version.ipynb)\n",
        "\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) \n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb)\n",
        "- [Tensorflow concepts](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n",
        "- [First steps with TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n",
        "- [Intro to neural nets](/notebooks/mlcc/intro_to_neural_nets.ipynb)\n",
        "- [Intro to sparse data and embeddings](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)\n",
        "\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "## Machine Learning Examples: Seedbank\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out the [Seedbank](https://research.google.com/seedbank/) project.\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Neural Style Transfer](https://research.google.com/seedbank/seed/neural_style_transfer_with_tfkeras): Use deep learning to transfer style between images.\n",
        "- [EZ NSynth](https://research.google.com/seedbank/seed/ez_nsynth): Synthesize audio with WaveNet auto-encoders.\n",
        "- [Fashion MNIST with Keras and TPUs](https://research.google.com/seedbank/seed/fashion_mnist_with_keras_and_tpus): Classify fashion-related images with deep learning.\n",
        "- [DeepDream](https://research.google.com/seedbank/seed/deepdream): Produce DeepDream images from your own photos.\n",
        "- [Convolutional VAE](https://research.google.com/seedbank/seed/convolutional_vae): Create a generative model of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Snx2y9kOI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os, argparse\n",
        "import cv2, spacy, numpy as np\n",
        "import keras\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.applications.vgg16 import VGG16 \n",
        "from keras.models import model_from_json\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.externals import joblib\n",
        "from keras import backend as K\n",
        "from keras.utils.vis_utils import plot_model\n",
        "K.set_image_data_format('channels_first')\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjkhCCiwktDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image_model_without():\n",
        "    ''' Takes the CNN weights file, and returns the VGG model update \n",
        "    with the weights. Requires the file VGG.py inside models/CNN '''\n",
        "    image_model = VGG_16()\n",
        "    image_model.layers.pop()\n",
        "    image_model.layers.pop()\n",
        "    # this is standard VGG 16 without the last two layers\n",
        "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    # one may experiment with \"adam\" optimizer, but the loss function for\n",
        "    # this kind of task is pretty standard\n",
        "    image_model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
        "    return image_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR4_K0hMkz3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e489efa3-8745-4246-9763-8e90d9729c6a"
      },
      "source": [
        "model = VGG16(weights=\"imagenet\", include_top=False)\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3, None, None)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, None, None)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, None, None)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, None, None)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, None, None)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, None, None)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 128, None, None)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 256, None, None)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 256, None, None)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 256, None, None)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 256, None, None)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 512, None, None)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 512, None, None)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 512, None, None)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aykCoGOklOst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_features(dataset, pre_model):\n",
        " \n",
        "    x_scratch = []\n",
        " \n",
        "    # loop over the images\n",
        "    for imagePath in dataset:\n",
        " \n",
        "        # load the input image and image is resized to 224x224 pixels\n",
        "        image = load_img(imagePath, target_size=(224, 224))\n",
        "        image = img_to_array(image)\n",
        " \n",
        "        # preprocess the image by (1) expanding the dimensions and\n",
        "        # (2) subtracting the mean RGB pixel intensity from the\n",
        "        # ImageNet dataset\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        image = imagenet_utils.preprocess_input(image)\n",
        " \n",
        "        # add the image to the batch\n",
        "        x_scratch.append(image)\n",
        " \n",
        "    x = np.vstack(x_scratch)\n",
        "    features = pre_model.predict(x, batch_size=32)\n",
        "    features_flatten = features.reshape((features.shape[0], 7 * 7 * 512))\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efmINP4OlSrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l7BKqxulzXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/bin/Xray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKpivB13l2qC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = []\n",
        "# r=root, d=directories, f = files\n",
        "for r, d, f in os.walk(path):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            files.append(os.path.join(r, file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5UGcOXql5l-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2252bd9b-47c0-4c0a-852b-91917a43c1e2"
      },
      "source": [
        "print(files)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/bin/Xray/39.jpg', '/bin/Xray/9.jpg', '/bin/Xray/56.jpg', '/bin/Xray/5.jpg', '/bin/Xray/23.jpg', '/bin/Xray/15.jpg', '/bin/Xray/8.jpg', '/bin/Xray/29.jpg', '/bin/Xray/13.jpg', '/bin/Xray/28.jpg', '/bin/Xray/35.jpg', '/bin/Xray/10.jpg', '/bin/Xray/3.jpg', '/bin/Xray/33.jpg', '/bin/Xray/20.jpg', '/bin/Xray/4.jpg', '/bin/Xray/53.jpg', '/bin/Xray/37.jpg', '/bin/Xray/58.jpg', '/bin/Xray/36.jpg', '/bin/Xray/2.jpg', '/bin/Xray/43.jpg', '/bin/Xray/7.jpg', '/bin/Xray/17.jpg', '/bin/Xray/42.jpg', '/bin/Xray/24.jpg', '/bin/Xray/46.jpg', '/bin/Xray/32.jpg', '/bin/Xray/54.jpg', '/bin/Xray/41.jpg', '/bin/Xray/6.jpg', '/bin/Xray/18.jpg', '/bin/Xray/19.jpg', '/bin/Xray/34.jpg', '/bin/Xray/16.jpg', '/bin/Xray/21.jpg', '/bin/Xray/25.jpg', '/bin/Xray/47.jpg', '/bin/Xray/40.jpg', '/bin/Xray/55.jpg', '/bin/Xray/31.jpg', '/bin/Xray/26.jpg', '/bin/Xray/22.jpg', '/bin/Xray/12.jpg', '/bin/Xray/38.jpg', '/bin/Xray/27.jpg', '/bin/Xray/50.jpg', '/bin/Xray/49.jpg', '/bin/Xray/11.jpg', '/bin/Xray/1.jpg', '/bin/Xray/30.jpg', '/bin/Xray/59.jpg', '/bin/Xray/14.jpg', '/bin/Xray/48.jpg', '/bin/Xray/45.jpg', '/bin/Xray/57.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZkXVdQzmC5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "8122f398-4f4b-42cf-ec75-bdb30acfb312"
      },
      "source": [
        "#sample image\n",
        "from IPython.display import Image\n",
        "Image(filename='/bin/Xray/9.jpg') "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxMTEhUTExMWFRUVFRcXFxYVFxcVFRcXFRUWFxUV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\nhCEH/9k=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGAzRj6-mJGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D\n",
        "from keras.applications import imagenet_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6PHbnmQmt3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = create_features(files, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbG6Xg66m5Xw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05479969-39b4-486f-9777-1bbb0c413ac5"
      },
      "source": [
        "#features from sample image\n",
        "train_features[8]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  6.0280094 , 25.553444  , ..., 11.59653   ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        , 11.253768  , 19.656885  , ...,  6.1125584 ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [ 0.        ,  0.18008399,  0.        , ...,  0.        ,\n",
              "          3.9985805 ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [ 6.266992  , 18.66488   ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        , 17.747194  , 45.105698  , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        , 23.585632  , 40.547546  , ...,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [ 0.        ,  0.        , 15.479403  , ..., 12.441618  ,\n",
              "         10.58677   ,  0.        ],\n",
              "        [ 0.        ,  0.        , 56.15415   , ..., 10.979804  ,\n",
              "          4.8441234 ,  0.        ],\n",
              "        [ 0.        ,  5.486207  , 69.834015  , ...,  5.6354394 ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [ 0.        ,  9.456694  ,  2.4965544 , ...,  0.        ,\n",
              "          0.        ,  2.9702075 ],\n",
              "        [ 3.5368564 , 29.85986   , 15.598538  , ...,  0.        ,\n",
              "          0.        ,  6.2847824 ],\n",
              "        [ 0.        , 11.237252  ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  4.653246  ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  5.8144298 ,  0.        , ...,  0.        ,\n",
              "          0.        ,  6.0194564 ],\n",
              "        [ 5.3027706 , 11.774978  ,  0.        , ...,  0.        ,\n",
              "          0.        ,  4.94368   ]],\n",
              "\n",
              "       [[ 0.        ,  1.5136889 , 10.20909   , ...,  7.943451  ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  6.7747717 , 20.52765   , ...,  5.4733615 ,\n",
              "          1.1036063 ,  0.        ],\n",
              "        [ 0.        ,  5.6366363 ,  1.831731  , ...,  2.0738387 ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [ 0.        , 13.935493  , 14.114928  , ...,  0.        ,\n",
              "         11.003906  ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSz_a511nYXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9039a4fc-1623-444e-8c7c-a8449d65a432"
      },
      "source": [
        "train_features.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 512, 7, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6H_lOH3nmdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_question_features_without_fd(question):\n",
        "    ''' For a given question, a unicode string, returns the time series vector\n",
        "    with each word (token) transformed into a 300 dimension representation\n",
        "    calculated using Glove Vector '''\n",
        "    word_embeddings = spacy.load('en')\n",
        "    tokens = word_embeddings(question)\n",
        "    question_tensor = np.zeros((30, 96))\n",
        "    for j in range(len(tokens)):\n",
        "        question_tensor[j,:] = tokens[j].vector\n",
        "    return question_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm1hu8Vmnzg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_path = '/Xray/CSV'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJKNWzp_oUoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7rfA9n4oYjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_csv = pd.read_csv('/bin/Xray/CSV/training.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfvbeYevscc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d7131420-5e9d-4218-db04-863fc639b53e"
      },
      "source": [
        "training_csv.head(5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Imageid</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>is this xray</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Does this image has single or multiple facture</td>\n",
              "      <td>single</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Does this image have single or multiple facture</td>\n",
              "      <td>multiple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>is this xray showing foreign body</td>\n",
              "      <td>foreign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>is this xray</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Imageid                                         Question    Answer\n",
              "0        1                                     is this xray       yes\n",
              "1        2   Does this image has single or multiple facture    single\n",
              "2        3  Does this image have single or multiple facture  multiple\n",
              "3        4                is this xray showing foreign body   foreign\n",
              "4        5                                     is this xray       yes"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm3vhuX7osEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions=training_csv['Question'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q0SCzKtoxRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "016dd811-9221-4ddc-ff6c-d6aa371428d3"
      },
      "source": [
        "#sample questions for training\n",
        "questions[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is this xray'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niUhR1IPo30l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX= []\n",
        "questions_tensor = []\n",
        "for question in questions:\n",
        "  question_features = get_question_features_without_fd(question)\n",
        "  questions_tensor.append(question_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkcfxwXSrP40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9221ff98-805f-40a8-ea3f-277e2104c3fa"
      },
      "source": [
        "len(questions_tensor)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-5jnKKYwcEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1532701-9ab2-445d-f762-fac959c939d5"
      },
      "source": [
        "len(train_features)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB9lTO7vsjV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image,questions in zip(train_features,questions_tensor):\n",
        "  trainX.append([image,questions])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6lVm_wLxHRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e199009d-73a0-4ead-ff99-a9cb2b66fba4"
      },
      "source": [
        "np.array(trainX).shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIqtrZv3xMl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question_features_array = []\n",
        "image_features_array = []\n",
        "for x in trainX:\n",
        "  question_features_array.append(x[0])\n",
        "  image_features_array.append(x[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZRlcSZKxXeC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42fcf74e-b16e-4173-aecd-47489b0b854f"
      },
      "source": [
        "question_features_array[0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.       , 21.212252 ,  0.       , ...,  0.       ,\n",
              "         18.89872  ,  0.       ],\n",
              "        [ 0.       ,  6.5687494,  0.       , ...,  0.7074292,\n",
              "          6.3412294,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        ...,\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ]],\n",
              "\n",
              "       [[ 1.0684202,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  5.546841 , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        ...,\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  1.2990077, ...,  0.       ,\n",
              "          0.       ,  0.       ]],\n",
              "\n",
              "       [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        ...,\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       , 13.650496 ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  3.1958263,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        ...,\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "         12.171731 ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          2.8585303,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ]],\n",
              "\n",
              "       [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        ...,\n",
              "        [ 1.4135702,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  1.4100394],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  5.610489 ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          2.4459112,  1.8469317]],\n",
              "\n",
              "       [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        ...,\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ],\n",
              "        [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
              "          0.       ,  0.       ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI0C7jZ5xb9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "93e72880-fff9-4bde-d2f1-75c4f543d809"
      },
      "source": [
        "question_features_array = np.array(question_features_array)\n",
        "image_features_array = np.array(image_features_array)\n",
        "print(question_features_array.shape)\n",
        "print(image_features_array.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(56, 512, 7, 7)\n",
            "(56, 30, 96)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NpbPEX1xpsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = training_csv['Answer'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8eHV4rnx3FV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0640052-358c-47df-f182-9b80f522f1eb"
      },
      "source": [
        "trainY[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeh1CrqQyC-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "452f48de-db66-4842-9323-98e2c4867e9c"
      },
      "source": [
        "set_trainy = list(set(trainY))\n",
        "trainY_labels = []\n",
        "for y in trainY:\n",
        "  trainY_labels.append(set_trainy.index(y))\n",
        "print(trainY_labels)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 9, 7, 2, 8, 2, 6, 0, 0, 0, 0, 6, 4, 4, 5, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 7, 7, 7, 1, 1, 1, 1, 1, 1, 8, 8, 8, 8, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgFhfM7hyHuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY_cate = keras.utils.to_categorical(trainY_labels, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfZtaPUc4k9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0be00d5a-d2d2-4252-9316-b7d0f2acd9a4"
      },
      "source": [
        "\n",
        "word_embeddings = spacy.load('en')\n",
        "obama = word_embeddings(u\"obama\")\n",
        "putin = word_embeddings(u\"putin\")\n",
        "banana = word_embeddings(u\"banana\")\n",
        "monkey = word_embeddings(u\"monkey\")\n",
        "obama.similarity(putin)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4547074384807158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e90VXaOo5cFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "690e4161-2c10-414e-b651-8a90969f0da2"
      },
      "source": [
        "question_features_array.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 512, 7, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDRvpg9h5iOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "feadbe19-c6c7-47c4-9c37-9e2ba7298743"
      },
      "source": [
        "image_features_array.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 30, 96)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAFHmxnO-pAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_11mDC-6FHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "8d49d535-92b1-4fd6-9904-08c9a0bc19d0"
      },
      "source": [
        ""
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    474\u001b[0m                 set(v.dtype.base_dtype for v in values)) > 1:\n\u001b[0;32m--> 475\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# All types should match.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-db5d1535fc73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion_features_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_features_array\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1152\u001b[0m                        (axis, -expanded_num_dims, expanded_num_dims))\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6301\u001b[0m   \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6302\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6303\u001b[0;31m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   6304\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6305\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    498\u001b[0m                                 (prefix, dtype.name))\n\u001b[1;32m    499\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s that don't all match.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m               raise TypeError(\n",
            "\u001b[0;31mTypeError\u001b[0m: Tensors in list passed to 'values' of 'Pack' Op have types [float32, float64] that don't all match."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M65MWRFzB0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "b8af8392-de19-4c30-f08f-1aed66c1de63"
      },
      "source": [
        "our_vqa_model.fit([question_features_array,image_features_array],trainY_cate,5,10)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-5bfdbd63a0f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mour_vqa_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion_features_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_features_array\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY_cate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'our_vqa_model' is not defined"
          ]
        }
      ]
    }
  ]
}